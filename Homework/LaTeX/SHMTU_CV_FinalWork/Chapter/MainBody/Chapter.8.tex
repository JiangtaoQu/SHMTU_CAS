\chapter{Microsoft Visual C++的部署}
\label{chapter:8}

\section{NCNN API}

\subsection{工作流程}

ncnn是一个为移动端设计的高效神经网络前向计算框架。以下是使用ncnn的C++ API进行神经网络推断的基本步骤：

\begin{enumerate}

	\item \textbf{包含必要的头文件}

	在使用ncnn之前，需要包含必要的头文件。这通常包括ncnn的主要命名空间和一些辅助工具。

	\begin{lstlisting}[caption={导入OpenCV与NCNN},language=C++]
		#include <net.h>
		#include <opencv2/opencv.hpp>
	\end{lstlisting}

	\item \textbf{加载预训练模型和参数}

	ncnn可以从硬盘加载已经转换好的预训练模型，这些模型通常由其他框架（如Caffe、TensorFlow等）转换而来。

	\begin{lstlisting}[caption={加载权重文件},language=C++]
		ncnn::Net net;
		net.load_param("model.param");
		net.load_model("model.bin");
	\end{lstlisting}

	\item \textbf{预处理输入数据}

	根据模型的输入要求，对输入数据进行预处理。这可能包括缩放、裁剪、归一化等操作。

	\begin{lstlisting}[caption={读取图片并处理数据},language=C++]
		cv::Mat img = cv::imread("input.jpg");
		ncnn::Mat in = ncnn::Mat::from_pixels_resize(img.data, ncnn::Mat::PIXEL_BGR, img.cols, img.rows, model_input_width, model_input_height);
		in.substract_mean_normalize(mean_vals, norm_vals);
	\end{lstlisting}

	请注意，`mean\_vals` 和 `norm\_vals` 需要根据你的模型设置正确的均值和标准差。

	\item \textbf{创建提取器并设置输入}

	创建一个提取器对象，并将预处理后的数据设置为输入。

	\begin{lstlisting}[caption={设置输入输出},language=C++]
		ncnn::Extractor ex = net.create_extractor();
		ex.input("input_blob", in);
	\end{lstlisting}

	这里的`"input\_blob"`是模型中定义的输入层的名称，需要根据实际情况进行替换。

	\item \textbf{执行推断}

	调用提取器的`extract`方法来执行推断。

	\begin{lstlisting}[caption={推理},language=C++]
		ncnn::Mat out;
		ex.extract("output_blob", out);
	\end{lstlisting}

	这里的`"output\_blob"`是模型中定义的输出层的名称，需要根据实际情况进行替换。

	\item \textbf{后处理输出数据}

	根据需要对输出数据进行后处理，例如将结果解码为可读的格式或应用于其他任务。

\end{enumerate}

这些步骤提供了使用ncnn进行神经网络推断的基本框架。具体细节可能因模型和数据而异，需要根据具体情况进行调整。

\subsection{NCNN调用Vulkan进行GPU加速}

ncnn是一个高效的神经网络前向计算框架，支持使用Vulkan进行加速。Vulkan是一个跨平台的计算机图形和计算API，通常用于游戏和图形应用程序，但也可以用于加速神经网络的推理。

使用Vulkan加速ncnn的一般步骤如下：

\begin{enumerate}
	\item 安装Vulkan：首先，你需要在你的系统上安装Vulkan。这通常涉及到下载和安装Vulkan SDK，并配置相关的环境变量。具体的安装步骤可能因操作系统和硬件的不同而有所不同。
	\item 编译ncnn with Vulkan：在安装了Vulkan之后，你需要使用Vulkan来编译ncnn。这通常涉及到在编译ncnn时启用Vulkan支持。具体的编译步骤可能因ncnn的版本和你的开发环境而有所不同。
	\item 使用编译好的ncnn进行推理：一旦你使用Vulkan编译了ncnn，你就可以使用编译好的ncnn来进行神经网络的推理了。在推理时，ncnn会自动使用Vulkan进行加速。
\end{enumerate}

需要注意的是，使用Vulkan加速ncnn并不总是能提供显著的性能提升。这取决于多种因素，包括你的硬件、操作系统、ncnn的版本以及你正在运行的神经网络模型。在某些情况下，使用Vulkan可能会降低性能，因此在使用之前最好进行充分的测试和性能分析。

另外，ncnn还支持其他加速方式，如使用ARM NEON指令集进行加速等。你可以根据你的硬件和需求选择最适合的加速方式。

\begin{lstlisting}[caption={NCNN with Vulkan Initialization}, language=C++]
	#include "net.h"
	// ... 其他必要的NCNN和Vulkan头文件 ...

	int main() {
		// 初始化Vulkan设备和实例（伪代码）
		// vulkanDevice = initializeVulkanDevice(...);
		// vulkanQueueFamilyIndex = getVulkanQueueFamilyIndex(...);

		// 初始化NCNN网络，并启用Vulkan支持
		ncnn::Net net;
		net.opt.use_vulkan_compute = true;  // 启用Vulkan计算
		// 设置Vulkan设备和队列家族索引（如果有必要的话）
		// net.set_vulkan_device(vulkanDevice);
		// net.set_vulkan_queue_family_index(
		//     vulkanQueueFamilyIndex
		// );

		// 加载模型
		net.load_param("model.param");
		net.load_model("model.bin");

		// 准备输入数据（伪代码）
		// ncnn::Mat input = prepareInputData(...);

		// 运行网络进行推理
		// ncnn::Extractor extractor = net.create_extractor();
		// extractor.input("input_blob", input);
		// extractor.extract("output_blob", output);

		// 处理输出数据（伪代码）
		// processOutputData(output);

		return 0;
	}
\end{lstlisting}

\section{Visual Studio 解决方案}

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{Resources/Picture/vs}
	\caption{Visual Studio解决方案Project}
	\label{fig:vs}
\end{figure}

\begin{enumerate}
	\item SHMTU\_CAS\_OCR\_Demo\_VC
	\item NCNN\_CLI
	\item SHMTU\_CAS\_CLR\_ClassLibrary
	\item SHMTU\_CAS\_OCR\_CLR\_Connector\_ClassLibrary
	\item SHMTU\_CAS\_OCR\_Demo\_WPF
\end{enumerate}

\subsection{SHMTU\_CAS\_OCR\_Demo\_VC}

\subsection{NCNN\_CLI}

\subsection{SHMTU\_CAS\_CLR\_ClassLibrary}

\subsection{SHMTU\_CAS\_OCR\_CLR\_Connector\_ClassLibrary}

\subsection{SHMTU\_CAS\_OCR\_Demo\_WPF}

\section{第三方库}

\subsection{NCNN20240102}

Github上提供的预先构建的NCNN Release版本采用了Release构建类型，这种类型主要优化的是程序的运行速度，同时会去除调试信息以减小文件大小。然而，这样的构建版本并不适合在Visual Studio（VC）中进行调试，因为它不包含必要的调试符号和信息。为了能够在VC中顺利进行NCNN的调试工作，我决定直接从Github仓库中克隆原始的NCNN代码，并在本地使用适当的配置重新编译它，以确保生成的库文件包含完整的调试信息。

\subsection{Protobuf 3.11.2}

ONNX（Open Neural Network Exchange）是一种用于表示深度学习模型的开放标准，它使用Google的Protobuf（Protocol Buffers）来进行模型数据的序列化和反序列化。因此，要在使用NCNN处理ONNX模型时，Protobuf是一个必不可少的依赖项。根据NCNN的官方文档推荐，Protobuf 3.11.2版本与NCNN的兼容性较好。基于这一信息，我选择了这个版本进行编译，以确保后续工作的顺利进行。

\subsection{OpenCV 5.0.0}

在已经决定自己编译Protobuf和NCNN的情况下，我考虑到OpenCV（Open Source Computer Vision Library）也是一个经常与NCNN一起使用的库，而且它的最新版本可能会带来一些新的功能和性能提升。虽然当前的稳定版本是4.9.0，但OpenCV的5.x版本已经在开发过程中，并且其源代码已经在Github上公开。因此，我决定直接从Github上克隆OpenCV的5.x开发分支，并在本地进行编译，以生成最新的5.0.0版本。这样一来，我就可以在我的项目中使用到最新版本的OpenCV，同时确保它与我自己编译的NCNN和Protobuf库之间的兼容性。

\section{编译步骤}

\subsection{安装Visual Studio 2022}

\begin{enumerate}
	\item 前往Visual Studio官网（\url{https://visualstudio.microsoft.com/}）下载Visual Studio 2022安装程序。
	\item 运行安装程序，并根据提示选择需要的组件，例如Visual C++等。
	\item 等待安装完成，确保安装过程中没有错误。
\end{enumerate}

\subsection{安装CMake}

\begin{enumerate}
	\item 前往CMake官网（\url{https://cmake.org/}）下载适用于Windows的CMake安装程序。
	\item 运行安装程序，并按照默认设置进行安装。
	\item 将CMake添加到系统路径中，以便在命令行中使用。
\end{enumerate}

\subsection{编译Protobuf}

\subsubsection{一般步骤}

\begin{enumerate}
	\item 前往Protobuf的GitHub仓库（\url{https://github.com/protocolbuffers/protobuf}）克隆或下载源代码。
	\item 如果下载的是源代码压缩包，请解压到一个合适的目录。
	\item 打开命令行工具，进入Protobuf源代码目录。
	\item 使用CMake生成构建文件，例如运行命令：\texttt{cmake -G "Visual Studio 17 2022" ..}（根据实际情况调整生成器）。
	\item 使用Visual Studio或MSBuild编译生成的解决方案或项目文件。
	\item 编译完成后，将生成的库和头文件放置到适当的位置，以便后续使用。
\end{enumerate}

\subsection{安装Vulkan SDK}

\begin{enumerate}
	\item 前往Vulkan SDK的下载页面（\url{https://vulkan.lunarg.com/sdk/home}）下载适用于Windows的最新版Vulkan SDK安装程序。
	\item 运行安装程序，并按照提示进行安装。通常情况下，安装程序会自动配置环境变量和路径。
	\item 验证安装是否成功，可以通过检查Vulkan SDK的安装目录和相关的环境变量来确认。
\end{enumerate}

\subsection{编译NCNN}

\begin{enumerate}
	\item 前往NCNN的GitHub仓库（\url{https://github.com/Tencent/ncnn}）克隆源代码到本地计算机上。
	\item 打开命令行工具，进入NCNN源代码目录。
	\item 使用CMake生成构建文件，指定需要的编译器和其他配置选项。例如，运行命令：\texttt{cmake -DCMAKE\_BUILD\_TYPE=Release ..}。
	\item 使用Visual Studio或MSBuild编译生成的解决方案或项目文件。确保选择了正确的配置（例如Release）和平台（例如x64）。
	\item 编译完成后，将生成的库和头文件放置到适当的位置，以便在项目中使用。
\end{enumerate}

\subsection{编译OpenCV}

\begin{enumerate}
	\item 前往OpenCV的GitHub仓库（\url{https://github.com/opencv/opencv}）和opencv\_contrib仓库（\url{https://github.com/opencv/opencv_contrib}）克隆源代码。
	\item 创建一个构建目录，并在命令行工具中进入该目录。
	\item 使用CMake配置OpenCV的构建，指定源代码路径、构建路径和opencv\_contrib模块的路径。
	\item 根据需要配置其他CMake选项，例如启用或禁用特定的功能模块、指定编译器等。
	\item 使用Visual Studio或MSBuild编译生成的解决方案或项目文件。这可能需要一些时间，具体取决于您的计算机性能和配置选项。
	\item 编译完成后，您可以选择安装OpenCV库和头文件到系统目录，或者将它们复制到您的项目目录中以便使用。确保在您的项目中正确配置库路径和头文件路径。
\end{enumerate}

\section{CAS\_OCR.cpp}

\section{CAS\_OCR API的使用}

\section{运行截图}

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{Resources/Picture/vc_main}
	\caption{VC WinMain}
	\label{fig:vcmain}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{Resources/Picture/vc_main_memory}
	\caption{VC GUI 内存使用(加载模型后)}
	\label{fig:vcmainmemory}
\end{figure}

\section{内存占用分析}


